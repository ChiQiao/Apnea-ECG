{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T13:14:32.688554Z",
     "start_time": "2020-02-07T13:14:31.467103Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import shutil\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from distutils.dir_util import copy_tree\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T13:14:32.716471Z",
     "start_time": "2020-02-07T13:14:32.689582Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/joey3/Desktop/Apnea'\n",
    "raw_dir = 'C:/Users/joey3/Desktop/Apnea_Raw'\n",
    "train_df = pd.read_csv('../resources/File_train.csv')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T13:14:32.732428Z",
     "start_time": "2020-02-07T13:14:32.718466Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5, batch_size=8):\n",
    "    # Preparation work\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(\n",
    "            os.path.join(data_dir, x), \n",
    "            transform=data_transforms[x],\n",
    "        ) \n",
    "        for x in ['train', 'val']\n",
    "    }\n",
    "    dataloaders = {\n",
    "        x: torch.utils.data.DataLoader(\n",
    "            image_datasets[x], \n",
    "            batch_size=batch_size,\n",
    "            shuffle=True, \n",
    "            num_workers=8,\n",
    "        )\n",
    "        for x in ['train', 'val']\n",
    "    }\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    class_names = image_datasets['train'].classes\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T13:14:32.741405Z",
     "start_time": "2020-02-07T13:14:32.733425Z"
    }
   },
   "outputs": [],
   "source": [
    "def val_performance(model, batch_size=8):\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    running_count, running_corrects = 0, 0\n",
    "    y_true, y_pred_prob = [], []\n",
    "    # Iterate over testing patients\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    image_datasets = datasets.ImageFolder(\n",
    "        f'{data_dir}/val', \n",
    "        transform=data_transforms,\n",
    "    ) \n",
    "    dataloaders = torch.utils.data.DataLoader(\n",
    "        image_datasets, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, \n",
    "        num_workers=8,\n",
    "    )\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dataloaders:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # statistics\n",
    "        running_count += len(preds)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        # Record result\n",
    "        y_true += labels.data.tolist()\n",
    "        y_pred_prob += outputs.tolist()\n",
    "        \n",
    "    epoch_acc = running_corrects.double() / running_count\n",
    "    print('Testing Acc: {:.4f}'.format(epoch_acc))\n",
    "    return y_true, y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T13:14:32.750381Z",
     "start_time": "2020-02-07T13:14:32.742402Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_cv(file_df, model, criterion, optimizer, scheduler, num_epochs=5, batch_size=8, n=4):\n",
    "    skf = StratifiedKFold(n_splits=n)\n",
    "    y_true, y_pred = [], []\n",
    "    for idx_train, idx_val in skf.split(file_df, file_df['group']):\n",
    "        print('*' * 20)\n",
    "        print('Prepare folders')\n",
    "        shutil.rmtree(data_dir)\n",
    "        os.mkdir(data_dir)\n",
    "        os.mkdir(f'{data_dir}/train')\n",
    "        os.mkdir(f'{data_dir}/train/0')\n",
    "        os.mkdir(f'{data_dir}/train/1')\n",
    "        os.mkdir(f'{data_dir}/val')\n",
    "        os.mkdir(f'{data_dir}/val/0')\n",
    "        os.mkdir(f'{data_dir}/val/1')\n",
    "        file_train, file_val = file_df.loc[idx_train, 'file'], file_df.loc[idx_val, 'file']\n",
    "        \n",
    "        # Prepare training image folders\n",
    "        for file in list(file_train):\n",
    "            copy_tree(f'{raw_dir}/{file}/0/', f'{data_dir}/train/0/', verbose=0)\n",
    "            copy_tree(f'{raw_dir}/{file}/1/', f'{data_dir}/train/1/', verbose=0)\n",
    "        \n",
    "        # Prepare validation image folders\n",
    "        for file in list(file_val):\n",
    "            copy_tree(f'{raw_dir}/{file}/0/', f'{data_dir}/val/0/', verbose=0)\n",
    "            copy_tree(f'{raw_dir}/{file}/1/', f'{data_dir}/val/1/', verbose=0)\n",
    "        \n",
    "        # Model training and reporting results on the validation set\n",
    "        print('Training starts')\n",
    "        model_trained = train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs, batch_size=batch_size)\n",
    "        y_true_, y_pred_prob_ = val_performance(model_trained, batch_size=batch_size)\n",
    "        y_true += y_true_\n",
    "        y_pred_prob += y_pred_prob_\n",
    "        \n",
    "    return y_true, y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:04:18.828020Z",
     "start_time": "2020-02-07T13:14:32.751378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Prepare folders\n",
      "Training starts\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.4282 Acc: 0.8078\n",
      "val Loss: 0.5154 Acc: 0.7930\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.3655 Acc: 0.8456\n",
      "val Loss: 0.4641 Acc: 0.8057\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.3496 Acc: 0.8518\n",
      "val Loss: 0.4753 Acc: 0.8086\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.3404 Acc: 0.8562\n",
      "val Loss: 0.4789 Acc: 0.8074\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.3329 Acc: 0.8577\n",
      "val Loss: 0.4989 Acc: 0.8119\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.3294 Acc: 0.8639\n",
      "val Loss: 0.4585 Acc: 0.8170\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.3209 Acc: 0.8654\n",
      "val Loss: 0.5075 Acc: 0.8149\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.2971 Acc: 0.8760\n",
      "val Loss: 0.4874 Acc: 0.8212\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.2911 Acc: 0.8798\n",
      "val Loss: 0.4773 Acc: 0.8189\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.2894 Acc: 0.8823\n",
      "val Loss: 0.4818 Acc: 0.8203\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.2872 Acc: 0.8810\n",
      "val Loss: 0.4878 Acc: 0.8245\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.2849 Acc: 0.8803\n",
      "val Loss: 0.4888 Acc: 0.8277\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.2831 Acc: 0.8835\n",
      "val Loss: 0.4697 Acc: 0.8245\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.2832 Acc: 0.8821\n",
      "val Loss: 0.4820 Acc: 0.8241\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.2767 Acc: 0.8864\n",
      "val Loss: 0.4820 Acc: 0.8284\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.2759 Acc: 0.8878\n",
      "val Loss: 0.4814 Acc: 0.8281\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.2755 Acc: 0.8873\n",
      "val Loss: 0.4782 Acc: 0.8283\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.2760 Acc: 0.8867\n",
      "val Loss: 0.4788 Acc: 0.8284\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.2759 Acc: 0.8870\n",
      "val Loss: 0.4795 Acc: 0.8289\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.2750 Acc: 0.8882\n",
      "val Loss: 0.4779 Acc: 0.8289\n",
      "\n",
      "Training complete in 49m 13s\n",
      "Best val Acc: 0.828855\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'y_pred_prob' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3323a2094206>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     batch_size=8, n=4)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-5e4e039aaa4a>\u001b[0m in \u001b[0;36mtrain_model_cv\u001b[1;34m(file_df, model, criterion, optimizer, scheduler, num_epochs, batch_size, n)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training starts'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mmodel_trained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0my_true_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_prob_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_trained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0my_true_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0my_pred_prob\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0my_pred_prob_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-cf177df8f17b>\u001b[0m in \u001b[0;36mval_performance\u001b[1;34m(model, batch_size)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Record result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0my_pred_prob\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mepoch_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunning_corrects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrunning_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'y_pred_prob' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# SqueezeNet\n",
    "model_ft = models.squeezenet1_0(pretrained=True)\n",
    "model_ft.classifier[1] = torch.nn.Conv2d(512, 2, kernel_size=(1,1), stride=(1,1))\n",
    "model_ft.num_classes = 2\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "y_true, y_pred_prob = train_model_cv(\n",
    "    train_df, model_ft, \n",
    "    criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20, \n",
    "    batch_size=8, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:04:18.828020Z",
     "start_time": "2020-02-07T13:14:31.492Z"
    }
   },
   "outputs": [],
   "source": [
    "res = {'y_true': y_true, 'y_pred_prob': y_pred_prob}\n",
    "with open('../archive/Model_CNN_CV_prob.pkl', 'wb') as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:04:18.828020Z",
     "start_time": "2020-02-07T13:14:31.494Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
