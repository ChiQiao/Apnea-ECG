{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:09:24.813964Z",
     "start_time": "2020-02-02T04:09:24.190544Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:09:29.548600Z",
     "start_time": "2020-02-02T04:09:29.413987Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '../../../Desktop/Apnea'\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), \n",
    "        transform=data_transforms[x],\n",
    "    ) \n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], \n",
    "        batch_size=8,\n",
    "        shuffle=True, \n",
    "        num_workers=6,\n",
    "    )\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:09:32.208296Z",
     "start_time": "2020-02-02T04:09:32.198296Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:28:47.342601Z",
     "start_time": "2020-02-02T04:28:47.330837Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    running_count, running_corrects = 0, 0\n",
    "    test_df = pd.read_csv('resources/File_test.csv')\n",
    "    # Iterate over testing patients\n",
    "    for file in test_df['file']:\n",
    "        image_datasets = datasets.ImageFolder(\n",
    "            f'{data_dir}/test/{file}', \n",
    "            transform=data_transforms['val'],\n",
    "        ) \n",
    "        dataloaders = torch.utils.data.DataLoader(\n",
    "            image_datasets, \n",
    "            batch_size=8,\n",
    "            shuffle=True, \n",
    "            num_workers=6,\n",
    "        )\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            running_count += len(preds)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_acc = running_corrects.double() / running_count\n",
    "    print('Testing Acc: {:.4f}'.format(epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:26:49.823904Z",
     "start_time": "2020-02-02T04:11:17.215782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.4157 Acc: 0.8280\n",
      "val Loss: 0.3950 Acc: 0.8694\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.3570 Acc: 0.8590\n",
      "val Loss: 0.3490 Acc: 0.8692\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.3257 Acc: 0.8731\n",
      "val Loss: 0.3279 Acc: 0.8588\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.3028 Acc: 0.8793\n",
      "val Loss: 0.3067 Acc: 0.8743\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2912 Acc: 0.8850\n",
      "val Loss: 0.3964 Acc: 0.8685\n",
      "\n",
      "Training complete in 15m 31s\n",
      "Best val Acc: 0.874256\n"
     ]
    }
   ],
   "source": [
    "# ResNet18\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = torch.nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)\n",
    "torch.save(model_ft, 'resources/resnet.pt')\n",
    "test_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:30:26.044900Z",
     "start_time": "2020-02-02T04:28:53.529048Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Acc: 0.7839\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T05:14:00.706667Z",
     "start_time": "2020-02-02T04:59:53.513777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.4030 Acc: 0.8250\n",
      "val Loss: 0.3604 Acc: 0.8512\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.3636 Acc: 0.8488\n",
      "val Loss: 0.3521 Acc: 0.8490\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.3523 Acc: 0.8568\n",
      "val Loss: 0.3349 Acc: 0.8616\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.3420 Acc: 0.8572\n",
      "val Loss: 0.3420 Acc: 0.8596\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.3342 Acc: 0.8635\n",
      "val Loss: 0.3283 Acc: 0.8679\n",
      "\n",
      "Training complete in 12m 34s\n",
      "Best val Acc: 0.867932\n",
      "Testing Acc: 0.7880\n"
     ]
    }
   ],
   "source": [
    "# SqueezeNet\n",
    "model_ft_2 = models.squeezenet1_0(pretrained=True)\n",
    "model_ft_2.classifier[1] = torch.nn.Conv2d(512, 2, kernel_size=(1,1), stride=(1,1))\n",
    "model_ft_2.num_classes = 2\n",
    "model_ft_2 = model_ft_2.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer_ft = torch.optim.SGD(model_ft_2.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft_2 = train_model(model_ft_2, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)\n",
    "torch.save(model_ft_2, 'resources/squeezenet.pt')\n",
    "test_model(model_ft_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:57:03.191819Z",
     "start_time": "2020-02-02T04:32:16.351126Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to C:\\Users\\joey3/.cache\\torch\\checkpoints\\googlenet-1378be20.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d57a570947c474da43dd7c4037d95d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52147035.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.4036 Acc: 0.8306\n",
      "val Loss: 0.3455 Acc: 0.8715\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.3450 Acc: 0.8603\n",
      "val Loss: 0.3053 Acc: 0.8815\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.3159 Acc: 0.8700\n",
      "val Loss: 0.3021 Acc: 0.8789\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.2970 Acc: 0.8803\n",
      "val Loss: 0.4343 Acc: 0.8240\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2807 Acc: 0.8869\n",
      "val Loss: 0.2991 Acc: 0.8810\n",
      "\n",
      "Training complete in 23m 2s\n",
      "Best val Acc: 0.881510\n",
      "Testing Acc: 0.7783\n"
     ]
    }
   ],
   "source": [
    "# GoogLeNet\n",
    "model_ft_3 = models.googlenet(pretrained=True)\n",
    "num_ftrs = model_ft_3.fc.in_features\n",
    "model_ft_3.fc = torch.nn.Linear(num_ftrs, 2)\n",
    "model_ft_3 = model_ft_3.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer_ft = torch.optim.SGD(model_ft_3.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft_3 = train_model(model_ft_3, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)\n",
    "torch.save(model_ft_3, 'resources/googlenet.pt')\n",
    "test_model(model_ft_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
