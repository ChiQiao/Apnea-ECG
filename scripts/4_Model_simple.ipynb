{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('dark_background')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('features/feature_train.csv')\n",
    "train_df = pd.read_csv('resources/File_train.csv')\n",
    "feature_col = df.drop(labels=['apn', 'group', 'file'], axis=1).columns\n",
    "label_col = 'apn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. L1 regularization\n",
    "    For Logistic Regression\n",
    "    - The baseline model shows a 3% difference between training and validation accuracy\n",
    "    - With L1 regularization the difference reduced to 2%, but overall accuracy decreased by 6%\n",
    "    For Linear SVC\n",
    "    - The baseline model performs worse than Logistic Regression\n",
    "    - With L1 regularization, the performance get improved\n",
    "    - Convergence issue is severe, so the findings above might not be accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "logreg_1 = LogisticRegression(solver='lbfgs', max_iter=1e6)\n",
    "acc_train, acc_val, _ = model_evaluation_CV(logreg_1, df, train_df, feature_col)\n",
    "print(f'Baseline performance: {acc_train:.3f} for training, {acc_val:.3f} for validation')\n",
    "\n",
    "# Baseline model + L1 (C=0.01)\n",
    "logreg_2 = LogisticRegression(C=0.01, penalty=\"l1\", dual=False, solver='saga', max_iter=1e6)\n",
    "acc_train, acc_val, _ = model_evaluation_CV(logreg_2, df, train_df, feature_col)\n",
    "print(f'With L1 (C=0.01): {acc_train:.3f} for training, {acc_val:.3f} for validation')\n",
    "\n",
    "# Baseline model + L1 (C=1)\n",
    "logreg_3 = LogisticRegression(C=1, penalty=\"l1\", dual=False, solver='saga', max_iter=1e6)\n",
    "acc_train, acc_val, _ = model_evaluation_CV(logreg_3, df, train_df, feature_col)\n",
    "print(f'With L1 (C=1): {acc_train:.3f} for training, {acc_val:.3f} for validation')\n",
    "\n",
    "# SVC baseline\n",
    "lsvc = LinearSVC(max_iter=1e6)\n",
    "acc_train, acc_val, _ = model_evaluation_CV(lsvc, df, train_df, feature_col)\n",
    "print(f'Baseline for Linear SVC: {acc_train:.3f} for training, {acc_val:.3f} for validation')\n",
    "\n",
    "# SVC (C=0.01)\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter=1e6)\n",
    "acc_train, acc_val, _ = model_evaluation_CV(lsvc, df, train_df, feature_col)\n",
    "print(f'Linear SVC (C=0.01): {acc_train:.3f} for training, {acc_val:.3f} for validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. With normalization\n",
    "    Normalization mitigates convergence issue\n",
    "    For different models and hyperparameters, validation accuracy is ~0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance: 0.858 for training, 0.827 for validation\n",
      "With L1 (C=0.01): 0.843 for training, 0.818 for validation\n",
      "With L1 (C=1): 0.858 for training, 0.827 for validation\n",
      "Baseline for Linear SVC: 0.858 for training, 0.827 for validation\n",
      "Linear SVC (C=0.01): 0.853 for training, 0.828 for validation\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "logreg_1 = LogisticRegression(solver='lbfgs', max_iter=1e6)\n",
    "acc_train, acc_val = util.model_evaluation_CV(logreg_1, df, train_df, feature_col, normalize=True)\n",
    "print(f'Baseline performance: {acc_train:.3f} for training, {acc_val:.3f} for validation')\n",
    "\n",
    "# Baseline model + L1 (C=0.01)\n",
    "logreg_2 = LogisticRegression(C=0.01, penalty=\"l1\", dual=False, solver='saga', max_iter=1e6)\n",
    "acc_train, acc_val = util.model_evaluation_CV(logreg_2, df, train_df, feature_col, normalize=True)\n",
    "print(f'With L1 (C=0.01): {acc_train:.3f} for training, {acc_val:.3f} for validation')\n",
    "\n",
    "# Baseline model + L1 (C=1)\n",
    "logreg_3 = LogisticRegression(C=1, penalty=\"l1\", dual=False, solver='saga', max_iter=1e6)\n",
    "acc_train, acc_val = util.model_evaluation_CV(logreg_3, df, train_df, feature_col, normalize=True)\n",
    "print(f'With L1 (C=1): {acc_train:.3f} for training, {acc_val:.3f} for validation')\n",
    "\n",
    "# SVC baseline\n",
    "lsvc = LinearSVC(max_iter=1e6)\n",
    "acc_train, acc_val = util.model_evaluation_CV(lsvc, df, train_df, feature_col, normalize=True)\n",
    "print(f'Baseline for Linear SVC: {acc_train:.3f} for training, {acc_val:.3f} for validation')\n",
    "\n",
    "# SVC (C=0.01)\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter=1e6)\n",
    "acc_train, acc_val = util.model_evaluation_CV(lsvc, df, train_df, feature_col, normalize=True)\n",
    "print(f'Linear SVC (C=0.01): {acc_train:.3f} for training, {acc_val:.3f} for validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z\n",
    "# Test L1 regularization (feature selection) with different models and hyperparameters\n",
    "X, y = df[feature_col], df[label_col]\n",
    "print(X.shape)\n",
    "\n",
    "file_train, file_val = train_test_split(train_df['file'], test_size=0.2, stratify=train_df['group'], random_state=123)\n",
    "X_train, X_val = df.loc[df.file.isin(file_train), feature_col], df.loc[df.file.isin(file_val), feature_col]\n",
    "y_train, y_val = df.loc[df.file.isin(file_train), label_col], df.loc[df.file.isin(file_val), label_col]\n",
    "\n",
    "logreg_1 = LogisticRegression(C=0.01, penalty=\"l1\", dual=False, solver='saga', max_iter=1e4).fit(X_train, y_train)\n",
    "print(logreg_1.score(X_train, y_train))\n",
    "print(logreg_1.score(X_val, y_val))\n",
    "model = SelectFromModel(logreg_1, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "print(X_new.shape)\n",
    "print(X.columns[np.invert(model.get_support())])\n",
    "\n",
    "logreg_2 = LogisticRegression(C=1, penalty=\"l1\", dual=False, solver='saga', max_iter=1e4).fit(X_train, y_train)\n",
    "model = SelectFromModel(logreg_2, prefit=True)\n",
    "print(logreg_2.score(X_train, y_train))\n",
    "print(logreg_2.score(X_val, y_val))\n",
    "X_new = model.transform(X)\n",
    "print(X_new.shape)\n",
    "print(X.columns[np.invert(model.get_support())])\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter=1e4).fit(X_train, y_train)\n",
    "print(lsvc.score(X_train, y_train))\n",
    "print(lsvc.score(X_val, y_val))\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "print(X_new.shape)\n",
    "print(X.columns[np.invert(model.get_support())])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
