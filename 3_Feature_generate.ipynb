{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Low level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart rate time history image with color label for each hour\n",
    "file_full = [f'a{i:02d}' for i in range(1, 21)] + \\\n",
    "    [f'b{i:02d}' for i in range(1, 6)] + \\\n",
    "    [f'c{i:02d}' for i in range(1, 11)]\n",
    "\n",
    "for file in file_full:\n",
    "    print(file)\n",
    "    with open('data/raw/' + file + '.pkl', 'rb') as f:\n",
    "        res = pickle.load(f)\n",
    "\n",
    "    total_hour = int(len(res['apn']) / 60) + 1\n",
    "    for hour in range(total_hour):\n",
    "        minute_start = hour * 60\n",
    "        if hour == total_hour - 1:\n",
    "            minute_end = len(res['apn'])\n",
    "        else:\n",
    "            minute_end = (hour + 1) * 60\n",
    "            \n",
    "        fig = util.plot_hr_apn(res, minute_start, minute_end)\n",
    "        fig.write_image('image_HR/' + f'{file}_minute{minute_start}.png',scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart rate data for each patient\n",
    "file_full = [f'a{i:02d}' for i in range(1, 21)] + \\\n",
    "    [f'b{i:02d}' for i in range(1, 6)] + \\\n",
    "    [f'c{i:02d}' for i in range(1, 11)] + \\\n",
    "    [f'x{i:02d}' for i in range(1, 36)]\n",
    "\n",
    "for file in file_full:\n",
    "    print(file)\n",
    "    with open('data/processed/' + file + '.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    t_hr, hr = [], []\n",
    "    for minute in range(len(data['apn'])):\n",
    "        t_hr_, hr_ = util.get_heart_rate(data['ecg'][minute])\n",
    "        t_hr_ = t_hr_ / 60 + minute # Unit in minutes\n",
    "        t_hr.append(t_hr_)\n",
    "        hr.append(hr_)    \n",
    "        \n",
    "    hr = np.hstack(hr)\n",
    "    t_hr = np.hstack(t_hr)\n",
    "    res = {'hr': hr, 't': t_hr}\n",
    "    with open('features/HR_' + file + '.pkl', 'wb') as f:\n",
    "        pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. High level features for model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hrvanalysis import get_time_domain_features, get_csi_cvi_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import signal\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_names):\n",
    "    df = pd.DataFrame()\n",
    "    b, a = signal.butter(3, 0.1)\n",
    "    fs_new = 2.4 # optimized from hyper-parameter tuning\n",
    "\n",
    "    for file in file_names:\n",
    "        print(file)\n",
    "        \n",
    "        # Load files\n",
    "        with open('data/processed/' + file + '.pkl', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "            apn = res['apn']\n",
    "            group = util.ecg_diagnose(apn) if file[0] == 'x' else file[0].upper() \n",
    "\n",
    "        with open('features/HR_' + file + '.pkl', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "            hr = res['hr']\n",
    "            t_hr = res['t'] # in minute\n",
    "            \n",
    "        # Remove outliers \n",
    "        idx_valid = (hr < 2) & (hr > 0.5)\n",
    "        hr, t_hr = hr[idx_valid], t_hr[idx_valid]\n",
    "        \n",
    "        # Filter out high-frequency noise\n",
    "        hr_smth = signal.filtfilt(b, a, hr)\n",
    "        \n",
    "        # Resample data for frequency-domain analysis\n",
    "        t_interp = np.arange(t_hr[0], t_hr[-1], 1 / fs_new / 60)\n",
    "        hr_interp = np.interp(t_interp, t_hr, hr_smth)\n",
    "        \n",
    "        # Extract features from each segment\n",
    "        for minute in range(len(apn) - 4):\n",
    "            fea_dict = {}\n",
    "            idx_1min = (t_hr > minute + 2) & (t_hr < minute + 3)\n",
    "            idx_5min = (t_hr > minute) & (t_hr < minute + 5)\n",
    "            data_1min, data_5min = hr_smth[idx_1min], hr_smth[idx_5min]\n",
    "            \n",
    "            hr_interp_1min = hr_interp[(t_interp > minute + 2) & (t_interp < minute + 3)]\n",
    "            hr_interp_5min = hr_interp[(t_interp > minute) & (t_interp < minute + 5)]\n",
    "            \n",
    "            # Discard segment if less than 30 heart beats detected\n",
    "            if len(data_1min) < 30: \n",
    "                continue\n",
    "                \n",
    "            # Time-domain features for data_1min\n",
    "            md = np.median(data_1min)\n",
    "            fea_dict.update({\n",
    "                'md_1min': md,\n",
    "                'min_r_1min': data_1min.min() - md,\n",
    "                'max_r_1min': data_1min.max() - md,\n",
    "                'p25_r_1min': np.percentile(data_1min, 0.25) - md,\n",
    "                'p75_r_1min': np.percentile(data_1min, 0.75) - md,\n",
    "                'mean_r_1min': data_1min.mean() - md,\n",
    "                'std_1min': data_1min.std(),\n",
    "                'acf1_1min': pd.Series(hr_interp_1min).autocorr(12),\n",
    "                'acf2_1min': pd.Series(hr_interp_1min).autocorr(24),\n",
    "            })\n",
    "            \n",
    "            # Time-domain features for data_5min\n",
    "            md = np.median(data_5min)\n",
    "            fea_dict.update({\n",
    "                'md_5min': md,\n",
    "                'min_r_5min': data_5min.min() - md,\n",
    "                'max_r_5min': data_5min.max() - md,\n",
    "                'p25_r_5min': np.percentile(data_5min, 0.25) - md,\n",
    "                'p75_r_5min': np.percentile(data_5min, 0.75) - md,\n",
    "                'mean_r_5min': data_5min.mean() - md,\n",
    "                'std_5min': data_5min.std(),\n",
    "                'acf1_5min': pd.Series(hr_interp_5min).autocorr(12),\n",
    "                'acf2_5min': pd.Series(hr_interp_5min).autocorr(24),\n",
    "            })\n",
    "            \n",
    "            # Heart rate variability\n",
    "            nn_intervals = (np.diff(t_hr[idx_1min]) * 1000 * 60).astype(int) # Unit in ms\n",
    "            time_domain_features = get_time_domain_features(nn_intervals)\n",
    "            nonlinear_features = get_csi_cvi_features(nn_intervals)\n",
    "            fea_dict.update(time_domain_features)\n",
    "            fea_dict.update(nonlinear_features)\n",
    "            \n",
    "            # Frequency-domain features\n",
    "            freqs, psd = signal.welch(\n",
    "                x=hr_interp_5min, \n",
    "                fs=fs_new)\n",
    "            fea_dict.update({\n",
    "                'peak': psd.max(),\n",
    "                'f_peak': freqs[np.argmax(psd)],\n",
    "                'area_total': psd.sum(),\n",
    "                'area_lf': psd[freqs < 1e-2].sum(),\n",
    "                'area_hf': psd[freqs > 1e-2].sum(),\n",
    "                'area_ratio': psd[freqs > 1e-2].sum() / psd[freqs < 1e-2].sum(),\n",
    "            })\n",
    "            \n",
    "            # Label information\n",
    "            fea_dict.update({\n",
    "                'apn': apn[minute + 2],\n",
    "                'group': group,\n",
    "                'file': file,\n",
    "            })\n",
    "            df = df.append(fea_dict, ignore_index=True)\n",
    "                    \n",
    "    df['apn'] = df['apn'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x32\n",
      "a13\n",
      "c09\n",
      "x29\n",
      "b02\n",
      "c03\n",
      "x16\n",
      "a08\n",
      "a15\n",
      "x34\n",
      "a14\n",
      "a12\n",
      "a07\n",
      "c05\n",
      "a04\n",
      "a06\n",
      "x28\n",
      "a09\n",
      "b01\n",
      "x33\n",
      "c10\n",
      "c04\n",
      "a16\n",
      "x20\n",
      "a10\n",
      "a19\n",
      "x27\n",
      "x01\n",
      "x07\n",
      "x19\n",
      "a17\n",
      "b05\n",
      "x18\n",
      "b04\n",
      "x11\n",
      "x17\n",
      "a05\n",
      "x22\n",
      "x35\n",
      "x31\n",
      "x13\n",
      "a01\n",
      "c02\n",
      "x24\n",
      "x21\n",
      "x02\n",
      "x08\n",
      "x09\n",
      "x14\n",
      "b03\n",
      "c08\n",
      "a11\n",
      "a02\n",
      "x30\n",
      "x12\n",
      "c07\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('resources/File_train.csv')\n",
    "df = extract_features(train_df['file'])\n",
    "df.dropna(inplace=True)\n",
    "df.to_csv('features/feature_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x03\n",
      "x23\n",
      "x05\n",
      "x26\n",
      "c01\n",
      "x04\n",
      "x10\n",
      "x06\n",
      "c06\n",
      "x25\n",
      "x15\n",
      "a03\n",
      "a18\n",
      "a20\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('resources/File_test.csv')\n",
    "for file in test_df['file']:\n",
    "    df = extract_features([file])\n",
    "    df.dropna(inplace=True)\n",
    "    df.to_csv('resources/feature_' + file + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z_3. Spectrum for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectrum(file_names):\n",
    "    df = pd.DataFrame()\n",
    "    b, a = signal.butter(3, 0.1)\n",
    "    fs_new = 2.4 # optimized from hyper-parameter tuning\n",
    "    fea = []\n",
    "\n",
    "    for file in file_names:\n",
    "        # Load files\n",
    "        with open('data/processed/' + file + '.pkl', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "            apn = res['apn']\n",
    "            group = util.ecg_diagnose(apn) if file[0] == 'x' else file[0].upper() \n",
    "\n",
    "        with open('features/HR_' + file + '.pkl', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "            hr = res['hr']\n",
    "            t_hr = res['t'] # in minute\n",
    "            \n",
    "        # Remove outliers \n",
    "        idx_valid = (hr < 2) & (hr > 0.5)\n",
    "        hr, t_hr = hr[idx_valid], t_hr[idx_valid]\n",
    "        \n",
    "        # Filter out high-frequency noise\n",
    "        hr_smth = signal.filtfilt(b, a, hr)\n",
    "        \n",
    "        # Resample data for frequency-domain analysis\n",
    "        t_interp = np.arange(t_hr[0], t_hr[-1], 1 / fs_new / 60)\n",
    "        hr_interp = np.interp(t_interp, t_hr, hr_smth)\n",
    "        \n",
    "        # Extract features from each segment\n",
    "        for minute in range(len(apn) - 4):\n",
    "            idx_5min = (t_hr > minute) & (t_hr < minute + 5)\n",
    "            data_5min = hr_smth[idx_5min]\n",
    "            \n",
    "            # Discard segment if less than 30 heart beats detected\n",
    "            if len(data_5min) < 30: \n",
    "                continue\n",
    "                \n",
    "            # Frequency-domain features\n",
    "            freqs, psd = signal.welch(\n",
    "                x=hr_interp[(t_interp > minute) & (t_interp < minute + 5)], \n",
    "                fs=fs_new)\n",
    "            fea.append([\n",
    "                psd.max(), freqs[np.argmax(psd)], \n",
    "                psd[freqs < 1e-2].sum(), psd[freqs > 1e-2].sum(), \n",
    "                psd[freqs > 1e-2].sum() / psd[freqs < 1e-2].sum(),\n",
    "                *psd[freqs < 0.1], \n",
    "            ])\n",
    "            # Label information\n",
    "            df = df.append({\n",
    "                'apn': apn[minute + 2],\n",
    "                'group': group,\n",
    "                'file': file,\n",
    "            }, ignore_index=True)\n",
    "                    \n",
    "    df['apn'] = df['apn'].astype(int)\n",
    "    fea = np.vstack(fea)\n",
    "    df = pd.concat([df, pd.DataFrame(fea)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('resources\\File_train.csv')\n",
    "df = extract_spectrum(train_df['file'])\n",
    "df.to_csv('features/mlp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
