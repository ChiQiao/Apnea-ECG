{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import importlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import util\n",
    "import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_mean(data, window_size=200):\n",
    "    weights = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, weights, mode='same')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_psd(file_names, seg_num=5, fs_new=2.4):\n",
    "    b, a = signal.butter(3, 0.1)\n",
    "    df = pd.DataFrame()\n",
    "    psd_1, psd_2 = [], []\n",
    "    \n",
    "    for file in file_names:\n",
    "        with open('data/processed/' + file + '.pkl', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "            apn = res['apn']\n",
    "\n",
    "        with open('features/HR_' + file + '.pkl', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "            hr = res['hr']\n",
    "            t_hr = res['t'] # in minute\n",
    "\n",
    "        # Remove outliers (defined as hr > 2)\n",
    "        idx_valid = (hr < 2) & (hr > 0.5)\n",
    "        hr = hr[idx_valid]\n",
    "        t_hr = t_hr[idx_valid]\n",
    "\n",
    "        # Filter out noise\n",
    "        hr_smth = signal.filtfilt(b, a, hr)\n",
    "\n",
    "        # Resample data\n",
    "        t_interp = np.arange(t_hr[0], t_hr[-1], 1 / fs_new / 60)\n",
    "        hr_interp = np.interp(t_interp, t_hr, hr_smth)\n",
    "        \n",
    "        group = util.ecg_diagnose(apn) if file[0] == 'x' else file[0].upper() \n",
    "        for minute in range(len(apn) - 4):\n",
    "            # 5-min window\n",
    "            hr_cur = hr_interp[(t_interp > minute) & (t_interp < minute + 5)]\n",
    "            freq, psd_ = signal.periodogram(\n",
    "                x=hr_cur, \n",
    "                fs=fs_new)\n",
    "            psd_1.append(psd_)\n",
    "            \n",
    "            # 3-min window\n",
    "            hr_cur = hr_interp[(t_interp > minute + 1) & (t_interp < minute + 4)]\n",
    "            _, psd_ = signal.periodogram(\n",
    "                x=hr_cur, \n",
    "                fs=fs_new)\n",
    "            psd_2.append(psd_)\n",
    "            \n",
    "            df = df.append({\n",
    "                'apn': apn[minute + 2],\n",
    "                'file': file,\n",
    "                'group': group,\n",
    "            }, ignore_index=True)\n",
    "        \n",
    "    df['apn'] = df['apn'].astype(int)\n",
    "#     psd_1, psd_2 = np.vstack(psd_1), np.vstack(psd_2)\n",
    "    return df, freq, psd_1, psd_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('resources\\File_train.csv')\n",
    "df, freq, psd_1, psd_2 = extract_psd(train_df['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_psd(psd_list, freq, f_thres):\n",
    "    fea = []\n",
    "    for psd in psd_list:\n",
    "        area_total = psd.sum()\n",
    "        area_lf = psd[freq < f_thres].sum()\n",
    "        area_hf = psd[freq > f_thres].sum()\n",
    "        fea.append([\n",
    "            psd.max(),\n",
    "            freq[np.argmax(psd)],\n",
    "            area_total,\n",
    "            area_lf,\n",
    "            area_hf,\n",
    "            area_lf / area_total,\n",
    "            area_hf / area_total,\n",
    "            area_lf / area_hf,\n",
    "        ])\n",
    "        \n",
    "    return fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize threshold for 5-min psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 358 but corresponding boolean dimension is 360",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-151832268e43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf_thres\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_psd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsd_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_thres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mfea_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfea\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfeature_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfea_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'apn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'group'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-ad96f77df673>\u001b[0m in \u001b[0;36mfeature_psd\u001b[1;34m(psd_list, freq, f_thres)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpsd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpsd_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0marea_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0marea_lf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfreq\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mf_thres\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0marea_hf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfreq\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mf_thres\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         fea.append([\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 358 but corresponding boolean dimension is 360"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for f_thres in (2 * np.logspace(-3, -1, 30)):\n",
    "    fea = feature_psd(psd_1, freq, f_thres)\n",
    "    fea_df = pd.concat([df, pd.DataFrame(fea)], axis=1)\n",
    "    feature_col = fea_df.drop(labels=['apn', 'group', 'file'], axis=1).columns\n",
    "    mdl = LogisticRegression(solver='lbfgs', max_iter=1e4)\n",
    "    acc_train, acc_val = util.model_evaluation_CV(mdl, fea_df, train_df, feature_col, n=4, normalize=True)\n",
    "    res.append([f_thres, acc_val])\n",
    "        \n",
    "res = np.vstack(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0097878 , 0.80472232])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmax(res[:, 1])\n",
    "res[idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize threshold for 3-min psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for f_thres in (2 * np.logspace(-3, -1, 30)):\n",
    "    fea = feature_psd(psd_2, freq, f_thres)\n",
    "    fea_df = pd.concat([df, pd.DataFrame(fea)], axis=1)\n",
    "    feature_col = fea_df.drop(labels=['apn', 'group', 'file'], axis=1).columns\n",
    "    mdl = LogisticRegression(solver='lbfgs', max_iter=1e4)\n",
    "    acc_train, acc_val = util.model_evaluation_CV(mdl, fea_df, train_df, feature_col, n=4, normalize=True)\n",
    "    res.append([f_thres, acc_val])\n",
    "        \n",
    "res = np.vstack(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0097878 , 0.78938044])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmax(res[:, 1])\n",
    "res[idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_1 = feature_psd(psd_1, freq, 0.01)\n",
    "fea_2 = feature_psd(psd_2, freq, 0.01)\n",
    "fea_df = pd.concat([df, pd.DataFrame(np.hstack((fea_1, fea_2)))], axis=1)\n",
    "feature_col = fea_df.drop(labels=['apn', 'group', 'file'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = LogisticRegression(solver='lbfgs', max_iter=1e4)\n",
    "acc_train, acc_val = util.model_evaluation_CV(mdl, fea_df, train_df, feature_col, n=4, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_df = pd.concat([df, pd.DataFrame(fea)], axis=1)\n",
    "feature_col = fea_df.drop(labels=['apn', 'group', 'file'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
